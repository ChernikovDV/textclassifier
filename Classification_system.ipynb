{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lefaHUbJmtCc"
   },
   "outputs": [],
   "source": [
    "# LEARNING SYSTEM\n",
    "# PREPROCESSING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IpZ-gEqnQrS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import sklearn\n",
    "import torch\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nV45ViQNnmea"
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "path_to_txt_data = \"\"\n",
    "saved_path = \"\" # path to saved pytorch objects\n",
    "\n",
    "k = 300 # out1 layer of first neural network\n",
    "c = 300 # out2 layer of first neural network\n",
    "\n",
    "h = 50  # out1 layer of second neural network\n",
    "u = 50  # out2 layer of second neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYIV0Hwbm86w"
   },
   "outputs": [],
   "source": [
    "def preprocessing(path_to_txt):\n",
    "    df = pd.DataFrame(columns=['text', 'label']) # define dataframe\n",
    "    for files in os.walk('{}\\ham'.format(path)): # read all files with path .\\ham\n",
    "        for i in files[2]:\n",
    "            try:\n",
    "                f = open('{}\\ham'.format(path)+'\\\\'+i, newline=None)\n",
    "                sp = f.read()\n",
    "                sp = re.sub( r'[^a-z 0-9!.,$%&?\"]', '', sp) # symbols from Table 2\n",
    "                df = df.append({'text':sp, 'label':0}, ignore_index=True)\n",
    "                f.close()\n",
    "            except: pass\n",
    "    for files in os.walk('{}\\spam'.format(path)): # read all files with path .\\spam\n",
    "        for i in files[2]:\n",
    "            try:\n",
    "                f = open('{}\\spam'.format(path)+'\\\\'+i, newline=None)\n",
    "                sp = f.read()\n",
    "                sp = re.sub( r'[^a-z 0-9!.,$%&?\"]', '', sp) # symbols from Table 2\n",
    "                df = df.append({'text':sp, 'label':1}, ignore_index=True)\n",
    "                f.close()\n",
    "            except: pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5rf1_tboam4"
   },
   "outputs": [],
   "source": [
    "# feature selection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXq3jCFypGCA"
   },
   "outputs": [],
   "source": [
    "def latter_encoder(x):\n",
    "    if x == 'a':\n",
    "        return 65\n",
    "    elif x == 'b':\n",
    "        return 66\n",
    "    elif x == 'c':\n",
    "        return 67\n",
    "    elif x == 'd':\n",
    "        return 68\n",
    "    elif x == 'e':\n",
    "        return 69\n",
    "    elif x == 'f':\n",
    "        return 70\n",
    "    elif x == 'g':\n",
    "        return 71\n",
    "    elif x == 'h':\n",
    "        return 72\n",
    "    elif x == 'i':\n",
    "        return 73\n",
    "    elif x == 'j':\n",
    "        return 74\n",
    "    elif x == 'k':\n",
    "        return 75\n",
    "    elif x == 'l':\n",
    "        return 76\n",
    "    elif x == 'm':\n",
    "        return 77\n",
    "    elif x == 'n':\n",
    "        return 78\n",
    "    elif x == 'o':\n",
    "        return 79\n",
    "    elif x == 'p':\n",
    "        return 80\n",
    "    elif x == 'q':\n",
    "        return 81\n",
    "    elif x == 'r':\n",
    "        return 82\n",
    "    elif x == 's':\n",
    "        return 83\n",
    "    elif x == 't':\n",
    "        return 84\n",
    "    elif x == 'u':\n",
    "        return 85\n",
    "    elif x == 'v':\n",
    "        return 86\n",
    "    elif x == 'w':\n",
    "        return 87\n",
    "    elif x == 'x':\n",
    "        return 88\n",
    "    elif x == 'y':\n",
    "        return 89\n",
    "    elif x == 'z':\n",
    "        return 90\n",
    "    elif x == ' ':\n",
    "          return 32\n",
    "    elif x == '!':\n",
    "          return 33\n",
    "    elif x == '\"':\n",
    "          return 34\n",
    "    elif x == '#':\n",
    "          return 35\n",
    "    elif x == '$':\n",
    "          return 36\n",
    "    elif x == '%':\n",
    "          return 37\n",
    "    elif x == '&':\n",
    "          return 38\n",
    "    elif x == \"'\":\n",
    "          return 39\n",
    "    elif x == '(':\n",
    "          return 40\n",
    "    elif x == ')':\n",
    "          return 41\n",
    "    elif x == '*':\n",
    "          return 42\n",
    "    elif x == '+':\n",
    "          return 43\n",
    "    elif x == ',':\n",
    "          return 44\n",
    "    elif x == '-':\n",
    "          return 45\n",
    "    elif x == '.':\n",
    "          return 46\n",
    "    elif x == '/':\n",
    "          return 47\n",
    "    elif x == '0':\n",
    "          return 48\n",
    "    elif x == '1':\n",
    "          return 49\n",
    "    elif x == '2':\n",
    "          return 50\n",
    "    elif x == '3':\n",
    "          return 51\n",
    "    elif x == '4':\n",
    "          return 52\n",
    "    elif x == '5':\n",
    "          return 53\n",
    "    elif x == '6':\n",
    "          return 54\n",
    "    elif x == '7':\n",
    "          return 55\n",
    "    elif x == '8':\n",
    "          return 56\n",
    "    elif x == '9':\n",
    "          return 57\n",
    "    elif x == ':':\n",
    "          return 58\n",
    "    elif x == ';':\n",
    "          return 59\n",
    "    elif x == '<':\n",
    "          return 60\n",
    "    elif x == '=':\n",
    "          return 61\n",
    "    elif x == '>':\n",
    "          return 62\n",
    "    elif x == '?':\n",
    "          return 63\n",
    "    elif x == '@':\n",
    "          return 64\n",
    "    else: return 91\n",
    "\n",
    "def feature_selection(doc):\n",
    "    res = []\n",
    "    for i in range(len(doc)):\n",
    "        res.append((latter_encoder(doc[i])-32)/(91-32))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJm4aWCspXvj"
   },
   "outputs": [],
   "source": [
    "# Neural network for text presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQLy9QP2pdg4"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, Input, k, c):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(Input, k)\n",
    "        self.fc2 = nn.Linear(k, c)\n",
    "        self.fc3 = nn.Linear(c, Input)\n",
    "        self.fc1.bias = None\n",
    "        self.fc2.bias = None\n",
    "        self.fc3.bias = None\n",
    "        torch.nn.init.constant_(self.fc1.weight, 0.01)\n",
    "        torch.nn.init.constant_(self.fc2.weight, 0.01)\n",
    "        weights = torch.empty(2000, 2000)\n",
    "        torch.manual_seed(101)\n",
    "        torch.nn.init.xavier_uniform_(weights, gain=1)\n",
    "        self.fc3.weight.data = weights[:Input, :c]\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    def answer(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pjlJ0-2p8Uz"
   },
   "outputs": [],
   "source": [
    "# Learning of fisrt neural network with SGD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bU9yRfDaqI8m"
   },
   "outputs": [],
   "source": [
    "def learningFirstNn(df, c):\n",
    "    res = []\n",
    "    for ind in len(df):\n",
    "        vec = torch.Tensor(feature_selection(df.iloc[ ind, 0]))\n",
    "        net = Net(len(vec), c)\n",
    "        net = net\n",
    "        vec = vec\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        learning_rate = 3\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "        counter = 0\n",
    "        loss_pred = 0\n",
    "        for t in range(2000):\n",
    "            y_pred = net(vec)\n",
    "            loss = loss_fn(y_pred, vec)\n",
    "            if loss_pred == loss.data:\n",
    "                counter+=1\n",
    "                learning_rate = learning_rate/2\n",
    "                optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "            if counter >= 2:\n",
    "                counter = 0 \n",
    "                learning_rate = 5\n",
    "                optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "            if loss < 10**(-3):\n",
    "                print('{} {}'.format(ind, loss.data))\n",
    "                break\n",
    "            if t == 1999:\n",
    "                print('{} {}'.format(ind, loss.data))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_pred = loss.data\n",
    "        try:\n",
    "            res.append(torch.cat((net.answer(vec), torch.Tensor([df.iloc[ind, 1]]))))\n",
    "        except: \n",
    "            res.append(net.answer(vec))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmFw4SW2raPX"
   },
   "outputs": [],
   "source": [
    "# save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gg-pM98urvuG"
   },
   "outputs": [],
   "source": [
    "def saveToFile(saved_path, torchObj):\n",
    "    torch.save(torchObj, saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvT-wB-kr_mB"
   },
   "outputs": [],
   "source": [
    "# fit scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0e054eDtBWb"
   },
   "outputs": [],
   "source": [
    "def scaler_learn(res):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(res)\n",
    "    # use scaler.transform(vector) to apply scalling\n",
    "    return scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpQKVpE1tXIX"
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#classification models#\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8EJz690tqNb"
   },
   "outputs": [],
   "source": [
    "# neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ec4-Nxdtuzl"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, c, h, u):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(c, h)\n",
    "        self.dout1 = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(h, u)\n",
    "        self.dout2 = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(u, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight.data, gain=1)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight.data, gain=1)\n",
    "        torch.nn.init.xavier_uniform_(self.fc3.weight.data, gain=1)\n",
    "        self.fc1.bias = None\n",
    "        self.fc2.bias = None\n",
    "        self.fc3.bias = None\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.dout1(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.dout2(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8CN1Z1OXuKYT"
   },
   "outputs": [],
   "source": [
    "def learningSecondNn(res, c, h, u):\n",
    "    net = Net(c, h, u)\n",
    "    res = res[torch.randperm(res.size()[0])]\n",
    "    X_train, X_test, y_train, y_test = res[:6000, :-1], res[6000:, :-1], res[:6000, -1], res[6000:, -1]\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    learning_rate = 0.01\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    num_epochs = 2000\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "    for t in range(num_epochs):\n",
    "          X = Variable(X)\n",
    "          y = Variable(y)\n",
    "          y_pred = net(X)\n",
    "          loss = loss_fn(y_pred, y.view(-1,1))\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward(retain_graph=True)\n",
    "          optimizer.step()\n",
    "          print('epoch {}'.format(t), ' ',loss.data)\n",
    "          if loss.data < 0.1:\n",
    "            break\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AK7XQBuFvZBO"
   },
   "outputs": [],
   "source": [
    "# naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ImURRwinvu7h"
   },
   "outputs": [],
   "source": [
    "def nbc(res):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(res[:,:-1], res[:,-1], test_size=0.15)\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8Rx0Qh1wF5e"
   },
   "outputs": [],
   "source": [
    "## other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lx1rQEVBwNmv"
   },
   "outputs": [],
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFvxiWoRwVRq"
   },
   "outputs": [],
   "source": [
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "max_iter = [500, 1000]\n",
    "for i in solver:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(res[:,:-1], res[:,-1], test_size=0.15)\n",
    "    clf = LogisticRegression(max_iter=1000, solver=i).fit(X_train, y_train)\n",
    "    m = clf.score(X_test, y_test)\n",
    "    print(m, ' ',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6sdr0s4wuN-"
   },
   "outputs": [],
   "source": [
    "# random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JG9vQF4DwxM9"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "mypipeline = Pipeline([\n",
    "('scaler', minmaxScaler()),\n",
    "('forest', RandomForestClassifier())\n",
    "])\n",
    "params = {\n",
    "'forest__n_estimators': range(90, 120),\n",
    "'forest__min_samples_split': range(4, 7),\n",
    "'forest__min_samples_leaf': [1, 2],\n",
    "'forest__max_features': [50, 60],\n",
    "'forest__max_depth': range(40, 80) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpDrVyw6xeGj"
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "hyper_search = RandomizedSearchCV(mypipeline, param_grid_base, n_iter=5, scoring='accuracy',\n",
    "cv=cv, n_jobs=-1, refit=True, random_state=101,\n",
    "verbose=2)\n",
    "hyper_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCSW1YP_wxP5"
   },
   "outputs": [],
   "source": [
    "## metrics ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRv0b039wyhF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "def printMetrics(y_pred, y):\n",
    "    print(confusion_matrix(y,y_pred))\n",
    "    print(classification_report(y,y_pred))\n",
    "    print(accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBeqbRLdw70l"
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#######################\n",
    "#classification system#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1WDkoL_ya2N"
   },
   "outputs": [],
   "source": [
    "def myClassifier(txt_obj, scaler, net):\n",
    "    df = pd.DataFrame(columns=['text', 'label'])\n",
    "    df.append({'text':txt_obj, 'label':'Unknown'}, ignore_index=True)\n",
    "    vector = learningFirstNn(df, 300)\n",
    "    vector = scaler.transform(vector)\n",
    "    print('The answer of the classifier is ', net(vector))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classification_system.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
